{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:19.929424Z",
     "start_time": "2024-09-30T09:22:19.926290Z"
    }
   },
   "source": [
    "# here for libs\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:23.045844Z",
     "start_time": "2024-09-30T09:22:19.952814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NVIDIA CUDA\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    print(f\"Current GPU device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ],
   "id": "7f4792a7fa3563f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4070 SUPER\n",
      "Current GPU device: 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Project plan:\n",
    "https://docs.google.com/document/d/1o2FlMo1je0yv7LeCV_mMHfmbbjH_XfzrfiKAefOh450/edit"
   ],
   "id": "5ac9c3a4785c1b17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:23.565116Z",
     "start_time": "2024-09-30T09:22:23.400873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data import\n",
    "data = pd.read_csv('./dataset/diabetes_dataset00.csv')\n",
    "data.head()"
   ],
   "id": "c5c094fc7693d888",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             Target Genetic Markers Autoantibodies  \\\n",
       "0          Steroid-Induced Diabetes        Positive       Negative   \n",
       "1  Neonatal Diabetes Mellitus (NDM)        Positive       Negative   \n",
       "2                       Prediabetic        Positive       Positive   \n",
       "3                   Type 1 Diabetes        Negative       Positive   \n",
       "4                  Wolfram Syndrome        Negative       Negative   \n",
       "\n",
       "  Family History Environmental Factors  Insulin Levels  Age  BMI  \\\n",
       "0             No               Present              40   44   38   \n",
       "1             No               Present              13    1   17   \n",
       "2            Yes               Present              27   36   24   \n",
       "3             No               Present               8    7   16   \n",
       "4            Yes               Present              17   10   17   \n",
       "\n",
       "  Physical Activity Dietary Habits  ...  Pulmonary Function  \\\n",
       "0              High        Healthy  ...                  76   \n",
       "1              High        Healthy  ...                  60   \n",
       "2              High      Unhealthy  ...                  80   \n",
       "3               Low      Unhealthy  ...                  89   \n",
       "4              High        Healthy  ...                  41   \n",
       "\n",
       "   Cystic Fibrosis Diagnosis  Steroid Use History  Genetic Testing  \\\n",
       "0                         No                   No         Positive   \n",
       "1                        Yes                   No         Negative   \n",
       "2                        Yes                   No         Negative   \n",
       "3                        Yes                   No         Positive   \n",
       "4                         No                   No         Positive   \n",
       "\n",
       "  Neurological Assessments Liver Function Tests Digestive Enzyme Levels  \\\n",
       "0                        3               Normal                      56   \n",
       "1                        1               Normal                      28   \n",
       "2                        1             Abnormal                      55   \n",
       "3                        2             Abnormal                      60   \n",
       "4                        1               Normal                      24   \n",
       "\n",
       "        Urine Test Birth Weight Early Onset Symptoms  \n",
       "0  Ketones Present         2629                   No  \n",
       "1  Glucose Present         1881                  Yes  \n",
       "2  Ketones Present         3622                  Yes  \n",
       "3  Ketones Present         3542                   No  \n",
       "4  Protein Present         1770                   No  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Genetic Markers</th>\n",
       "      <th>Autoantibodies</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Environmental Factors</th>\n",
       "      <th>Insulin Levels</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Physical Activity</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>...</th>\n",
       "      <th>Pulmonary Function</th>\n",
       "      <th>Cystic Fibrosis Diagnosis</th>\n",
       "      <th>Steroid Use History</th>\n",
       "      <th>Genetic Testing</th>\n",
       "      <th>Neurological Assessments</th>\n",
       "      <th>Liver Function Tests</th>\n",
       "      <th>Digestive Enzyme Levels</th>\n",
       "      <th>Urine Test</th>\n",
       "      <th>Birth Weight</th>\n",
       "      <th>Early Onset Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steroid-Induced Diabetes</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>Normal</td>\n",
       "      <td>56</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>2629</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neonatal Diabetes Mellitus (NDM)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>28</td>\n",
       "      <td>Glucose Present</td>\n",
       "      <td>1881</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prediabetic</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Present</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>High</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>55</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>3622</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type 1 Diabetes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>Low</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>60</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>3542</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wolfram Syndrome</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Present</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24</td>\n",
       "      <td>Protein Present</td>\n",
       "      <td>1770</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.Preprocessing\n",
   "id": "d21af4f87de70822"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:23.664342Z",
     "start_time": "2024-09-30T09:22:23.620300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##check missing data\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]\n"
   ],
   "id": "c1beda73b90b8707",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:24.370579Z",
     "start_time": "2024-09-30T09:22:23.791591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##lable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "categorical_columns = ['Genetic Markers', 'Autoantibodies', 'Family History' , 'Environmental Factors', 'Dietary Habits', 'Ethnicity', 'Socioeconomic Factors', 'Smoking Status', 'Alcohol Consumption', 'Glucose Tolerance Test', 'Previous Gestational Diabetes', 'Pregnancy History', 'Cystic Fibrosis Diagnosis', 'Environmental Factors', 'Steroid Use History', 'Genetic Testing', 'Liver Function Tests', 'Urine Test', 'Early Onset Symptoms', 'Physical Activity', 'History of PCOS', 'Target']\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "output_file_path = './dataset/numeric_diabetes_dataset.csv'\n",
    "data.to_csv(output_file_path, index=False) \n",
    "\n",
    "\n",
    "\n",
    "data.head(50)\n",
    "\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "\n"
   ],
   "id": "1c9c465a14908746",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:24.456262Z",
     "start_time": "2024-09-30T09:22:24.378225Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.describe())\n",
   "id": "95f68e3d138b8523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Target  Genetic Markers  Autoantibodies  Family History  \\\n",
      "count  70000.000000     70000.000000    70000.000000    70000.000000   \n",
      "mean       5.989729         0.501443        0.499171        0.502400   \n",
      "std        3.737753         0.500001        0.500003        0.499998   \n",
      "min        0.000000         0.000000        0.000000        0.000000   \n",
      "25%        3.000000         0.000000        0.000000        0.000000   \n",
      "50%        6.000000         1.000000        0.000000        1.000000   \n",
      "75%        9.000000         1.000000        1.000000        1.000000   \n",
      "max       12.000000         1.000000        1.000000        1.000000   \n",
      "\n",
      "       Environmental Factors  Insulin Levels           Age           BMI  \\\n",
      "count           70000.000000    70000.000000  70000.000000  70000.000000   \n",
      "mean                0.498743       21.607443     32.020700     24.782943   \n",
      "std                 0.500002       10.785852     21.043173      6.014236   \n",
      "min                 0.000000        5.000000      0.000000     12.000000   \n",
      "25%                 0.000000       13.000000     14.000000     20.000000   \n",
      "50%                 0.000000       19.000000     31.000000     25.000000   \n",
      "75%                 1.000000       28.000000     49.000000     29.000000   \n",
      "max                 1.000000       49.000000     79.000000     39.000000   \n",
      "\n",
      "       Physical Activity  Dietary Habits  ...  Pulmonary Function  \\\n",
      "count       70000.000000    70000.000000  ...        70000.000000   \n",
      "mean            1.002886        0.499714  ...           70.264671   \n",
      "std             0.816369        0.500003  ...           11.965600   \n",
      "min             0.000000        0.000000  ...           30.000000   \n",
      "25%             0.000000        0.000000  ...           63.000000   \n",
      "50%             1.000000        0.000000  ...           72.000000   \n",
      "75%             2.000000        1.000000  ...           79.000000   \n",
      "max             2.000000        1.000000  ...           89.000000   \n",
      "\n",
      "       Cystic Fibrosis Diagnosis  Steroid Use History  Genetic Testing  \\\n",
      "count               70000.000000         70000.000000     70000.000000   \n",
      "mean                    0.498071             0.497971         0.504500   \n",
      "std                     0.500000             0.499999         0.499983   \n",
      "min                     0.000000             0.000000         0.000000   \n",
      "25%                     0.000000             0.000000         0.000000   \n",
      "50%                     0.000000             0.000000         1.000000   \n",
      "75%                     1.000000             1.000000         1.000000   \n",
      "max                     1.000000             1.000000         1.000000   \n",
      "\n",
      "       Neurological Assessments  Liver Function Tests  \\\n",
      "count              70000.000000          70000.000000   \n",
      "mean                   1.804157              0.500271   \n",
      "std                    0.680154              0.500003   \n",
      "min                    1.000000              0.000000   \n",
      "25%                    1.000000              0.000000   \n",
      "50%                    2.000000              1.000000   \n",
      "75%                    2.000000              1.000000   \n",
      "max                    3.000000              1.000000   \n",
      "\n",
      "       Digestive Enzyme Levels    Urine Test  Birth Weight  \\\n",
      "count             70000.000000  70000.000000  70000.000000   \n",
      "mean                 46.420529      1.505171   3097.061071   \n",
      "std                  19.391089      1.118669    713.837300   \n",
      "min                  10.000000      0.000000   1500.000000   \n",
      "25%                  31.000000      1.000000   2629.000000   \n",
      "50%                  48.000000      2.000000   3103.000000   \n",
      "75%                  61.000000      3.000000   3656.250000   \n",
      "max                  99.000000      3.000000   4499.000000   \n",
      "\n",
      "       Early Onset Symptoms  \n",
      "count          70000.000000  \n",
      "mean               0.499157  \n",
      "std                0.500003  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                0.000000  \n",
      "75%                1.000000  \n",
      "max                1.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.Validation methods",
   "id": "48b53611c9a36cf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 cross validation",
   "id": "212e767daf192fda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:24.487385Z",
     "start_time": "2024-09-30T09:22:24.482879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state) \n",
    "    indices = np.random.permutation(len(X))  \n",
    "    test_set_size = int(len(X) * test_size)  \n",
    "    test_indices = indices[:test_set_size]  \n",
    "    train_indices = indices[test_set_size:]  \n",
    "    \n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ],
   "id": "8d422868444ea729",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 k fold validation",
   "id": "3bd73d2b69c1f715"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9ad32111e49b9393"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:24.520077Z",
     "start_time": "2024-09-30T09:22:24.511569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_kfold(X, y, k=5, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    fold_size = len(X) // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        test_indices = indices[i*fold_size:(i+1)*fold_size]\n",
    "        train_indices = np.concatenate([indices[:i*fold_size], indices[(i+1)*fold_size:]])\n",
    "        folds.append((train_indices, test_indices))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "\n",
    "k_folds = manual_kfold(X, y, k=5, random_state=42)\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds):\n",
    "    print(f\"Fold {i+1}: Train size = {len(train_idx)}, Test size = {len(test_idx)}\")\n"
   ],
   "id": "405d53fbf8995f84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 56000, Test size = 14000\n",
      "Fold 2: Train size = 56000, Test size = 14000\n",
      "Fold 3: Train size = 56000, Test size = 14000\n",
      "Fold 4: Train size = 56000, Test size = 14000\n",
      "Fold 5: Train size = 56000, Test size = 14000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Bootstrapping",
   "id": "9ddd6b6d7df6fda8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:24.586286Z",
     "start_time": "2024-09-30T09:22:24.563643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "X_train, y_train = resample(X, y, n_samples=len(X), random_state=42)\n",
    "\n",
    "\n",
    "X_val = X[~X.index.isin(X_train.index)]\n",
    "y_val = y[~y.index.isin(y_train.index)]\n",
    "\n",
    "print(f\"train size: {X_train.shape}, val size: {X_val.shape}\")\n"
   ],
   "id": "e554817496aa59af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (70000, 33), val size: (25795, 33)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.ML algorithms and Experimental results",
   "id": "36629c0afab2358a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Simple algorithms: Random Forest",
   "id": "efc89c6152cc6710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:24:01.300484400Z",
     "start_time": "2024-09-30T09:23:54.109842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "train_sizes = np.concatenate(([0.01], np.logspace(-1, 0, 3)))  # [0.01, 0.1, 0.5, 1.0]\n",
    "n_repeats = 20  \n",
    "accuracies = []\n",
    "train_sizes_actual = []\n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "\n",
    "\n",
    "experiments_per_size = n_repeats // len(train_sizes)\n",
    "\n",
    "\n",
    "for size in train_sizes:\n",
    "    for i in range(experiments_per_size):\n",
    "        X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        \n",
    "       \n",
    "        subset_train_idx = X_train.index[:int(len(X_train) * size)]\n",
    "        X_train_subset = X_train.loc[subset_train_idx]\n",
    "        y_train_subset = y_train.loc[subset_train_idx]\n",
    "        \n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=None)\n",
    "        model.fit(X_train_subset, y_train_subset)\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        train_sizes_actual.append(len(X_train_subset))\n",
    "        \n",
    "        \n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "        print(f\"Experiment with Train Size {len(X_train_subset)}: Accuracy = {accuracy:.3f}\")\n",
    "\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "# learning curve\n",
    "plt.figure()\n",
    "plt.plot(train_sizes_actual, accuracies, marker='o', label='Accuracy')\n",
    "plt.title(\"Learning Curve with Train Sizes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Error bar\n",
    "plt.figure()\n",
    "plt.errorbar(x=train_sizes_actual, y=accuracies, yerr=std_accuracy, fmt='o', label='Accuracy with error bar')\n",
    "plt.title(\"Learning Curve with Error Bars\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#conf matrix\n",
    "conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(all_y_test, all_y_pred))\n"
   ],
   "id": "2a70a1bc22c32151",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Train Size 560: Accuracy = 0.789\n",
      "Experiment with Train Size 560: Accuracy = 0.760\n",
      "Experiment with Train Size 560: Accuracy = 0.799\n",
      "Experiment with Train Size 560: Accuracy = 0.769\n",
      "Experiment with Train Size 560: Accuracy = 0.781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 33\u001B[0m\n\u001B[0;32m     29\u001B[0m model \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     30\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train_subset, y_train_subset)\n\u001B[1;32m---> 33\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n\u001B[0;32m     35\u001B[0m accuracies\u001B[38;5;241m.\u001B[39mappend(accuracy)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001B[0m, in \u001B[0;36mForestClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    803\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;124;03m    Predict class for X.\u001B[39;00m\n\u001B[0;32m    805\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    821\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[0;32m    822\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 823\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    825\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    826\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39margmax(proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:876\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    871\u001B[0m all_proba \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    872\u001B[0m     np\u001B[38;5;241m.\u001B[39mzeros((X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], j), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39matleast_1d(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_)\n\u001B[0;32m    874\u001B[0m ]\n\u001B[0;32m    875\u001B[0m lock \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mLock()\n\u001B[1;32m--> 876\u001B[0m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequire\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msharedmem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_accumulate_prediction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlock\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimators_\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m proba \u001B[38;5;129;01min\u001B[39;00m all_proba:\n\u001B[0;32m    882\u001B[0m     proba \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:647\u001B[0m, in \u001B[0;36m_accumulate_prediction\u001B[1;34m(predict, X, out, lock)\u001B[0m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_accumulate_prediction\u001B[39m(predict, X, out, lock):\n\u001B[0;32m    641\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    642\u001B[0m \u001B[38;5;124;03m    This is a utility function for joblib's Parallel.\u001B[39;00m\n\u001B[0;32m    643\u001B[0m \n\u001B[0;32m    644\u001B[0m \u001B[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001B[39;00m\n\u001B[0;32m    645\u001B[0m \u001B[38;5;124;03m    complains that it cannot pickle it when placed there.\u001B[39;00m\n\u001B[0;32m    646\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 647\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    648\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m lock:\n\u001B[0;32m    649\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:993\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.predict_proba\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    991\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    992\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X, check_input)\n\u001B[1;32m--> 993\u001B[0m proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    995\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    996\u001B[0m     proba \u001B[38;5;241m=\u001B[39m proba[:, : \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:38.323253700Z",
     "start_time": "2024-09-28T13:02:08.281141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def nested_cross_validation(X, y, param_grid, k_outer=5, k_inner=3):\n",
    "    outer_folds = manual_kfold(X, y, k=k_outer, random_state=42)\n",
    "    outer_scores = []\n",
    "    \n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_folds):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        \n",
    "        inner_folds = manual_kfold(X_train_outer, y_train_outer, k=k_inner, random_state=42)\n",
    "        \n",
    "        for params in param_grid:\n",
    "            inner_scores = []\n",
    "            \n",
    "            \n",
    "            for inner_train_idx, inner_val_idx in inner_folds:\n",
    "                X_train_inner, X_val_inner = X_train_outer.iloc[inner_train_idx], X_train_outer.iloc[inner_val_idx]\n",
    "                y_train_inner, y_val_inner = y_train_outer.iloc[inner_train_idx], y_train_outer.iloc[inner_val_idx]\n",
    "                \n",
    "                model = RandomForestClassifier(n_estimators=params['n_estimators'], max_depth=params['max_depth'], random_state=42)\n",
    "                model.fit(X_train_inner, y_train_inner)\n",
    "                \n",
    "                y_val_pred = model.predict(X_val_inner)\n",
    "                inner_scores.append(accuracy_score(y_val_inner, y_val_pred))\n",
    "            \n",
    "            mean_inner_score = np.mean(inner_scores)\n",
    "            \n",
    "           \n",
    "            if mean_inner_score > best_score:\n",
    "                best_score = mean_inner_score\n",
    "                best_params = params\n",
    "        \n",
    "       \n",
    "        best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], random_state=42)\n",
    "        best_model.fit(X_train_outer, y_train_outer)\n",
    "        y_test_pred = best_model.predict(X_test_outer)\n",
    "        \n",
    "        test_accuracy = accuracy_score(y_test_outer, y_test_pred)\n",
    "        outer_scores.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1}: Best Params = {best_params}, Test Accuracy = {test_accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "    mean_score = np.mean(outer_scores)\n",
    "    std_score = np.std(outer_scores)\n",
    "    print(f\"Nested CV Mean Accuracy: {mean_score:.3f}, Std: {std_score:.3f}\")\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': 50, 'max_depth': 10},\n",
    "    {'n_estimators': 100, 'max_depth': 20},\n",
    "    {'n_estimators': 200, 'max_depth': None}\n",
    "]\n",
    "\n",
    "\n",
    "nested_cross_validation(X, y, param_grid)\n"
   ],
   "id": "dafd41df0411368b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.901\n",
      "Fold 2: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.906\n",
      "Fold 3: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.905\n",
      "Fold 4: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.904\n",
      "Fold 5: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.898\n",
      "Nested CV Mean Accuracy: 0.903, Std: 0.003\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Medium algorithms: MLP",
   "id": "99f807555018350f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "923c1cb73c7a7ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cd61492827ab58e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:22:38.324251600Z",
     "start_time": "2024-09-28T12:19:46.709845Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4a4cdff795127ee0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
