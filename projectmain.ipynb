{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:10.622415Z",
     "start_time": "2024-10-01T05:23:10.620414Z"
    }
   },
   "source": [
    "# here for libs\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:13.774234Z",
     "start_time": "2024-10-01T05:23:10.642144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NVIDIA CUDA\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    print(f\"Current GPU device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ],
   "id": "7f4792a7fa3563f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4070 SUPER\n",
      "Current GPU device: 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Project plan:\n",
    "https://docs.google.com/document/d/1o2FlMo1je0yv7LeCV_mMHfmbbjH_XfzrfiKAefOh450/edit"
   ],
   "id": "5ac9c3a4785c1b17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:14.318766Z",
     "start_time": "2024-10-01T05:23:14.128380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data import\n",
    "data = pd.read_csv('./dataset/diabetes_dataset00.csv')\n",
    "data.head()"
   ],
   "id": "c5c094fc7693d888",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             Target Genetic Markers Autoantibodies  \\\n",
       "0          Steroid-Induced Diabetes        Positive       Negative   \n",
       "1  Neonatal Diabetes Mellitus (NDM)        Positive       Negative   \n",
       "2                       Prediabetic        Positive       Positive   \n",
       "3                   Type 1 Diabetes        Negative       Positive   \n",
       "4                  Wolfram Syndrome        Negative       Negative   \n",
       "\n",
       "  Family History Environmental Factors  Insulin Levels  Age  BMI  \\\n",
       "0             No               Present              40   44   38   \n",
       "1             No               Present              13    1   17   \n",
       "2            Yes               Present              27   36   24   \n",
       "3             No               Present               8    7   16   \n",
       "4            Yes               Present              17   10   17   \n",
       "\n",
       "  Physical Activity Dietary Habits  ...  Pulmonary Function  \\\n",
       "0              High        Healthy  ...                  76   \n",
       "1              High        Healthy  ...                  60   \n",
       "2              High      Unhealthy  ...                  80   \n",
       "3               Low      Unhealthy  ...                  89   \n",
       "4              High        Healthy  ...                  41   \n",
       "\n",
       "   Cystic Fibrosis Diagnosis  Steroid Use History  Genetic Testing  \\\n",
       "0                         No                   No         Positive   \n",
       "1                        Yes                   No         Negative   \n",
       "2                        Yes                   No         Negative   \n",
       "3                        Yes                   No         Positive   \n",
       "4                         No                   No         Positive   \n",
       "\n",
       "  Neurological Assessments Liver Function Tests Digestive Enzyme Levels  \\\n",
       "0                        3               Normal                      56   \n",
       "1                        1               Normal                      28   \n",
       "2                        1             Abnormal                      55   \n",
       "3                        2             Abnormal                      60   \n",
       "4                        1               Normal                      24   \n",
       "\n",
       "        Urine Test Birth Weight Early Onset Symptoms  \n",
       "0  Ketones Present         2629                   No  \n",
       "1  Glucose Present         1881                  Yes  \n",
       "2  Ketones Present         3622                  Yes  \n",
       "3  Ketones Present         3542                   No  \n",
       "4  Protein Present         1770                   No  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Genetic Markers</th>\n",
       "      <th>Autoantibodies</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Environmental Factors</th>\n",
       "      <th>Insulin Levels</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Physical Activity</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>...</th>\n",
       "      <th>Pulmonary Function</th>\n",
       "      <th>Cystic Fibrosis Diagnosis</th>\n",
       "      <th>Steroid Use History</th>\n",
       "      <th>Genetic Testing</th>\n",
       "      <th>Neurological Assessments</th>\n",
       "      <th>Liver Function Tests</th>\n",
       "      <th>Digestive Enzyme Levels</th>\n",
       "      <th>Urine Test</th>\n",
       "      <th>Birth Weight</th>\n",
       "      <th>Early Onset Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steroid-Induced Diabetes</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>Normal</td>\n",
       "      <td>56</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>2629</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neonatal Diabetes Mellitus (NDM)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>28</td>\n",
       "      <td>Glucose Present</td>\n",
       "      <td>1881</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prediabetic</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Present</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>High</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>55</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>3622</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type 1 Diabetes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>Present</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>Low</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>60</td>\n",
       "      <td>Ketones Present</td>\n",
       "      <td>3542</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wolfram Syndrome</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Present</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>High</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24</td>\n",
       "      <td>Protein Present</td>\n",
       "      <td>1770</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.Preprocessing\n",
   "id": "d21af4f87de70822"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:14.416501Z",
     "start_time": "2024-10-01T05:23:14.376523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##check missing data\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]\n"
   ],
   "id": "c1beda73b90b8707",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:15.082712Z",
     "start_time": "2024-10-01T05:23:14.502091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##lable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "categorical_columns = ['Genetic Markers', 'Autoantibodies', 'Family History' , 'Environmental Factors', 'Dietary Habits', 'Ethnicity', 'Socioeconomic Factors', 'Smoking Status', 'Alcohol Consumption', 'Glucose Tolerance Test', 'Previous Gestational Diabetes', 'Pregnancy History', 'Cystic Fibrosis Diagnosis', 'Environmental Factors', 'Steroid Use History', 'Genetic Testing', 'Liver Function Tests', 'Urine Test', 'Early Onset Symptoms', 'Physical Activity', 'History of PCOS', 'Target']\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "output_file_path = './dataset/numeric_diabetes_dataset.csv'\n",
    "data.to_csv(output_file_path, index=False) \n",
    "\n",
    "\n",
    "\n",
    "data.head(50)\n",
    "\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "\n"
   ],
   "id": "1c9c465a14908746",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:15.190598Z",
     "start_time": "2024-10-01T05:23:15.090934Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.describe())\n",
   "id": "95f68e3d138b8523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Target  Genetic Markers  Autoantibodies  Family History  \\\n",
      "count  70000.000000     70000.000000    70000.000000    70000.000000   \n",
      "mean       5.989729         0.501443        0.499171        0.502400   \n",
      "std        3.737753         0.500001        0.500003        0.499998   \n",
      "min        0.000000         0.000000        0.000000        0.000000   \n",
      "25%        3.000000         0.000000        0.000000        0.000000   \n",
      "50%        6.000000         1.000000        0.000000        1.000000   \n",
      "75%        9.000000         1.000000        1.000000        1.000000   \n",
      "max       12.000000         1.000000        1.000000        1.000000   \n",
      "\n",
      "       Environmental Factors  Insulin Levels           Age           BMI  \\\n",
      "count           70000.000000    70000.000000  70000.000000  70000.000000   \n",
      "mean                0.498743       21.607443     32.020700     24.782943   \n",
      "std                 0.500002       10.785852     21.043173      6.014236   \n",
      "min                 0.000000        5.000000      0.000000     12.000000   \n",
      "25%                 0.000000       13.000000     14.000000     20.000000   \n",
      "50%                 0.000000       19.000000     31.000000     25.000000   \n",
      "75%                 1.000000       28.000000     49.000000     29.000000   \n",
      "max                 1.000000       49.000000     79.000000     39.000000   \n",
      "\n",
      "       Physical Activity  Dietary Habits  ...  Pulmonary Function  \\\n",
      "count       70000.000000    70000.000000  ...        70000.000000   \n",
      "mean            1.002886        0.499714  ...           70.264671   \n",
      "std             0.816369        0.500003  ...           11.965600   \n",
      "min             0.000000        0.000000  ...           30.000000   \n",
      "25%             0.000000        0.000000  ...           63.000000   \n",
      "50%             1.000000        0.000000  ...           72.000000   \n",
      "75%             2.000000        1.000000  ...           79.000000   \n",
      "max             2.000000        1.000000  ...           89.000000   \n",
      "\n",
      "       Cystic Fibrosis Diagnosis  Steroid Use History  Genetic Testing  \\\n",
      "count               70000.000000         70000.000000     70000.000000   \n",
      "mean                    0.498071             0.497971         0.504500   \n",
      "std                     0.500000             0.499999         0.499983   \n",
      "min                     0.000000             0.000000         0.000000   \n",
      "25%                     0.000000             0.000000         0.000000   \n",
      "50%                     0.000000             0.000000         1.000000   \n",
      "75%                     1.000000             1.000000         1.000000   \n",
      "max                     1.000000             1.000000         1.000000   \n",
      "\n",
      "       Neurological Assessments  Liver Function Tests  \\\n",
      "count              70000.000000          70000.000000   \n",
      "mean                   1.804157              0.500271   \n",
      "std                    0.680154              0.500003   \n",
      "min                    1.000000              0.000000   \n",
      "25%                    1.000000              0.000000   \n",
      "50%                    2.000000              1.000000   \n",
      "75%                    2.000000              1.000000   \n",
      "max                    3.000000              1.000000   \n",
      "\n",
      "       Digestive Enzyme Levels    Urine Test  Birth Weight  \\\n",
      "count             70000.000000  70000.000000  70000.000000   \n",
      "mean                 46.420529      1.505171   3097.061071   \n",
      "std                  19.391089      1.118669    713.837300   \n",
      "min                  10.000000      0.000000   1500.000000   \n",
      "25%                  31.000000      1.000000   2629.000000   \n",
      "50%                  48.000000      2.000000   3103.000000   \n",
      "75%                  61.000000      3.000000   3656.250000   \n",
      "max                  99.000000      3.000000   4499.000000   \n",
      "\n",
      "       Early Onset Symptoms  \n",
      "count          70000.000000  \n",
      "mean               0.499157  \n",
      "std                0.500003  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                0.000000  \n",
      "75%                1.000000  \n",
      "max                1.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.Validation methods",
   "id": "48b53611c9a36cf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 cross validation",
   "id": "212e767daf192fda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:15.246989Z",
     "start_time": "2024-10-01T05:23:15.241477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state) \n",
    "    indices = np.random.permutation(len(X))  \n",
    "    test_set_size = int(len(X) * test_size)  \n",
    "    test_indices = indices[:test_set_size]  \n",
    "    train_indices = indices[test_set_size:]  \n",
    "    \n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ],
   "id": "8d422868444ea729",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 k fold validation",
   "id": "3bd73d2b69c1f715"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9ad32111e49b9393"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:15.277101Z",
     "start_time": "2024-10-01T05:23:15.269592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_kfold(X, y, k=5, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    fold_size = len(X) // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        test_indices = indices[i*fold_size:(i+1)*fold_size]\n",
    "        train_indices = np.concatenate([indices[:i*fold_size], indices[(i+1)*fold_size:]])\n",
    "        folds.append((train_indices, test_indices))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "\n",
    "k_folds = manual_kfold(X, y, k=5, random_state=42)\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds):\n",
    "    print(f\"Fold {i+1}: Train size = {len(train_idx)}, Test size = {len(test_idx)}\")\n"
   ],
   "id": "405d53fbf8995f84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 56000, Test size = 14000\n",
      "Fold 2: Train size = 56000, Test size = 14000\n",
      "Fold 3: Train size = 56000, Test size = 14000\n",
      "Fold 4: Train size = 56000, Test size = 14000\n",
      "Fold 5: Train size = 56000, Test size = 14000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Bootstrapping",
   "id": "9ddd6b6d7df6fda8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:15.349844Z",
     "start_time": "2024-10-01T05:23:15.325804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "X_train, y_train = resample(X, y, n_samples=len(X), random_state=42)\n",
    "\n",
    "\n",
    "X_val = X[~X.index.isin(X_train.index)]\n",
    "y_val = y[~y.index.isin(y_train.index)]\n",
    "\n",
    "print(f\"train size: {X_train.shape}, val size: {X_val.shape}\")\n"
   ],
   "id": "e554817496aa59af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (70000, 33), val size: (25795, 33)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.ML algorithms and Experimental results",
   "id": "36629c0afab2358a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Simple algorithms: Random Forest",
   "id": "efc89c6152cc6710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-01T05:23:15.394906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "train_sizes = np.concatenate(([0.01], np.logspace(-1, 0, 3)))  # [0.01, 0.1, 0.5, 1.0]\n",
    "n_repeats = 20  \n",
    "accuracies = []\n",
    "train_sizes_actual = []\n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "\n",
    "\n",
    "experiments_per_size = n_repeats // len(train_sizes)\n",
    "\n",
    "\n",
    "for size in train_sizes:\n",
    "    for i in range(experiments_per_size):\n",
    "        X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        \n",
    "       \n",
    "        subset_train_idx = X_train.index[:int(len(X_train) * size)]\n",
    "        X_train_subset = X_train.loc[subset_train_idx]\n",
    "        y_train_subset = y_train.loc[subset_train_idx]\n",
    "        \n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=None)\n",
    "        model.fit(X_train_subset, y_train_subset)\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        train_sizes_actual.append(len(X_train_subset))\n",
    "        \n",
    "        \n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "        print(f\"Experiment with Train Size {len(X_train_subset)}: Accuracy = {accuracy:.3f}\")\n",
    "\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "# learning curve\n",
    "plt.figure()\n",
    "plt.plot(train_sizes_actual, accuracies, marker='o', label='Accuracy')\n",
    "plt.title(\"Learning Curve with Train Sizes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Error bar\n",
    "plt.figure()\n",
    "plt.errorbar(x=train_sizes_actual, y=accuracies, yerr=std_accuracy, fmt='o', label='Accuracy with error bar')\n",
    "plt.title(\"Learning Curve with Error Bars\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#conf matrix\n",
    "conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(all_y_test, all_y_pred))\n"
   ],
   "id": "2a70a1bc22c32151",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Train Size 560: Accuracy = 0.789\n",
      "Experiment with Train Size 560: Accuracy = 0.760\n",
      "Experiment with Train Size 560: Accuracy = 0.799\n",
      "Experiment with Train Size 560: Accuracy = 0.769\n",
      "Experiment with Train Size 560: Accuracy = 0.781\n",
      "Experiment with Train Size 5600: Accuracy = 0.887\n",
      "Experiment with Train Size 5600: Accuracy = 0.883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 30\u001B[0m\n\u001B[0;32m     26\u001B[0m y_train_subset \u001B[38;5;241m=\u001B[39m y_train\u001B[38;5;241m.\u001B[39mloc[subset_train_idx]\n\u001B[0;32m     29\u001B[0m model \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m---> 30\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_subset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m     34\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    445\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[0;32m    448\u001B[0m ]\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[1;32m--> 456\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    469\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    472\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    473\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:175\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    173\u001B[0m     curr_sample_weight \u001B[38;5;241m=\u001B[39m sample_weight\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m--> 175\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[43m_generate_sample_indices\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m sample_counts \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbincount(indices, minlength\u001B[38;5;241m=\u001B[39mn_samples)\n\u001B[0;32m    179\u001B[0m curr_sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m sample_counts\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:132\u001B[0m, in \u001B[0;36m_generate_sample_indices\u001B[1;34m(random_state, n_samples, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03mPrivate function used to _parallel_build_trees function.\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m random_instance \u001B[38;5;241m=\u001B[39m check_random_state(random_state)\n\u001B[1;32m--> 132\u001B[0m sample_indices \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sample_indices\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:26.362726900Z",
     "start_time": "2024-09-30T09:32:35.625363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def nested_cross_validation(X, y, param_grid, k_outer=5, k_inner=3):\n",
    "    outer_folds = manual_kfold(X, y, k=k_outer, random_state=42)\n",
    "    outer_scores = []\n",
    "    \n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_folds):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        \n",
    "        inner_folds = manual_kfold(X_train_outer, y_train_outer, k=k_inner, random_state=42)\n",
    "        \n",
    "        for params in param_grid:\n",
    "            inner_scores = []\n",
    "            \n",
    "            \n",
    "            for inner_train_idx, inner_val_idx in inner_folds:\n",
    "                X_train_inner, X_val_inner = X_train_outer.iloc[inner_train_idx], X_train_outer.iloc[inner_val_idx]\n",
    "                y_train_inner, y_val_inner = y_train_outer.iloc[inner_train_idx], y_train_outer.iloc[inner_val_idx]\n",
    "                \n",
    "                model = RandomForestClassifier(n_estimators=params['n_estimators'], max_depth=params['max_depth'], random_state=42)\n",
    "                model.fit(X_train_inner, y_train_inner)\n",
    "                \n",
    "                y_val_pred = model.predict(X_val_inner)\n",
    "                inner_scores.append(accuracy_score(y_val_inner, y_val_pred))\n",
    "            \n",
    "            mean_inner_score = np.mean(inner_scores)\n",
    "            \n",
    "           \n",
    "            if mean_inner_score > best_score:\n",
    "                best_score = mean_inner_score\n",
    "                best_params = params\n",
    "        \n",
    "       \n",
    "        best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], random_state=42)\n",
    "        best_model.fit(X_train_outer, y_train_outer)\n",
    "        y_test_pred = best_model.predict(X_test_outer)\n",
    "        \n",
    "        test_accuracy = accuracy_score(y_test_outer, y_test_pred)\n",
    "        outer_scores.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1}: Best Params = {best_params}, Test Accuracy = {test_accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "    mean_score = np.mean(outer_scores)\n",
    "    std_score = np.std(outer_scores)\n",
    "    print(f\"Nested CV Mean Accuracy: {mean_score:.3f}, Std: {std_score:.3f}\")\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': 50, 'max_depth': 10},\n",
    "    {'n_estimators': 100, 'max_depth': 20},\n",
    "    {'n_estimators': 200, 'max_depth': None}\n",
    "]\n",
    "\n",
    "\n",
    "nested_cross_validation(X, y, param_grid)\n"
   ],
   "id": "dafd41df0411368b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.901\n",
      "Fold 2: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.906\n",
      "Fold 3: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.905\n",
      "Fold 4: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.904\n",
      "Fold 5: Best Params = {'n_estimators': 200, 'max_depth': None}, Test Accuracy = 0.898\n",
      "Nested CV Mean Accuracy: 0.903, Std: 0.003\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Medium algorithms: MLP",
   "id": "99f807555018350f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:23:41.268479Z",
     "start_time": "2024-10-01T05:23:41.263960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ],
   "id": "aff0291452afcd76",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "923c1cb73c7a7ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:51:26.113226Z",
     "start_time": "2024-10-01T05:51:26.102196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_perceptron_pytorch(X_train_scaled, X_test_scaled, y_train, y_test, n_epochs=30, eta=0.01, optimizer='Adam', params=None):\n",
    "    # Convert Pandas DataFrames to NumPy arrays\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = X_train_scaled.to_numpy(), X_test_scaled.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = torch.from_numpy(X_train_scaled), torch.from_numpy(X_test_scaled), torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "    # Check number of classes\n",
    "    n_classes = len(torch.unique(y_train))\n",
    "\n",
    "    # Create iterable dataset in Torch format\n",
    "    train_ds = torch.utils.data.TensorDataset(X_train_scaled, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32)\n",
    "    test_ds = torch.utils.data.TensorDataset(X_test_scaled, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "    # Create the multi-layer perceptron model\n",
    "    model = nn.Sequential(\n",
    "            nn.Linear(33, 128, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(16, n_classes, dtype=torch.float64),\n",
    "            )\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use the provided or default parameters\n",
    "    if params:\n",
    "        n_epochs = params.get('n_epochs', n_epochs)\n",
    "        eta = params.get('eta', eta)\n",
    "        optimizer = params.get('optimizer', optimizer)\n",
    "\n",
    "\n",
    "    # Setup the optimizer. This implements the basic gradient descent update\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "    elif optimizer == 'Momentum':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.9)\n",
    "    elif optimizer == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=eta, eps=1e-10)\n",
    "    elif optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "    else:\n",
    "        raise ValueError('Invalid optimizer')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, (xi, yi) in enumerate(train_loader):\n",
    "            #Compute loss F(w)\n",
    "            yi = yi.long()\n",
    "            logits = model(xi)\n",
    "            loss = criterion(logits, yi)\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            train_acc = torch.mean(torch.eq(predictions, yi).float()).item()\n",
    "\n",
    "            loss.backward()               # Backward pass (compute parameter gradients)\n",
    "            optimizer.step()              # Update weight parameter using SGD\n",
    "            optimizer.zero_grad()         # Reset gradients to zero for next ieration\n",
    "\n",
    "    # Evaluate the model, not necessary for training\n",
    "    with torch.no_grad():\n",
    "        for xi, yi in test_loader:\n",
    "            yi = yi.long()\n",
    "            logits = model(xi)\n",
    "            loss = criterion(logits, yi)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            accuracy = torch.mean(torch.eq(predictions, yi).float()).item()\n",
    "\n",
    "    return accuracy"
   ],
   "id": "8712ceb1e9b2b93f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "503d2adbeab53deb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cd61492827ab58e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:51:45.191699500Z",
     "start_time": "2024-10-01T05:51:30.849903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nested_cross_validation(X, y, param_grid, outer_k=5, inner_k=3, n_epochs=30, eta=0.01, optimizer='Adam'):\n",
    "    outer_kf = manual_kfold(X, y, k=outer_k, random_state=42)\n",
    "    outer_scores = []\n",
    "\n",
    "    for outer_fold, (train_index, test_index) in enumerate(outer_kf):\n",
    "        #print(f\"Outer Fold {outer_fold + 1}\")\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "\n",
    "        inner_kf = manual_kfold(X_train, y_train, k=inner_k, random_state=42)\n",
    "\n",
    "        for params in param_grid:\n",
    "            inner_scores = []\n",
    "            for inner_fold, (inner_train_index, inner_val_index) in enumerate(inner_kf):\n",
    "                X_train_inner, X_val_inner = X_train.iloc[inner_train_index], X_train.iloc[inner_val_index]\n",
    "                y_train_inner, y_val_inner = y_train.iloc[inner_train_index], y_train.iloc[inner_val_index]\n",
    "\n",
    "                # Scaling\n",
    "                scaler = StandardScaler()\n",
    "                X_train_inner_scaled = scaler.fit_transform(X_train_inner)\n",
    "                X_val_inner_scaled = scaler.transform(X_val_inner)\n",
    "\n",
    "                # Convert to Pandas DataFrame\n",
    "                X_train_inner_scaled = pd.DataFrame(X_train_inner_scaled, columns=X_train_inner.columns)\n",
    "                X_val_inner_scaled = pd.DataFrame(X_val_inner_scaled, columns=X_val_inner.columns)\n",
    "\n",
    "                # Train model\n",
    "                val_acc = train_perceptron_pytorch(X_train_inner_scaled, X_val_inner_scaled, y_train_inner, y_val_inner, n_epochs, eta, optimizer, params)\n",
    "                inner_scores.append(val_acc)\n",
    "\n",
    "            mean_inner_score = np.mean(inner_scores)\n",
    "            if mean_inner_score > best_score:\n",
    "                best_score = mean_inner_score\n",
    "                best_params = params\n",
    "\n",
    "        # Train the model with the best parameters\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Convert to Pandas DataFrame\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "        test_acc = train_perceptron_pytorch(X_train_scaled, X_test_scaled, y_train, y_test, n_epochs, eta, optimizer, best_params)\n",
    "        outer_scores.append(test_acc)\n",
    "\n",
    "        print(f\"Outer Fold {outer_fold + 1}: Best Params = {best_params}, Test Accuracy = {test_acc:.3f}\")\n",
    "\n",
    "    mean_score = np.mean(outer_scores)\n",
    "    std_score = np.std(outer_scores)\n",
    "    print(f\"Nested CV Mean Accuracy: {mean_score:.3f}, Std: {std_score:.3f}\")\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'n_epochs': 20, 'eta': 0.01, 'optimizer': 'Momentum'},\n",
    "    {'n_epochs': 30, 'eta': 0.01, 'optimizer': 'Momentum'},\n",
    "    {'n_epochs': 20, 'eta': 0.01, 'optimizer': 'Adam'},\n",
    "    {'n_epochs': 30, 'eta': 0.01, 'optimizer': 'Adam'}\n",
    "]\n",
    "\n",
    "\n",
    "nested_cross_validation(X, y, param_grid, outer_k=5, inner_k=3, n_epochs=30, eta=0.01, optimizer='Adam')"
   ],
   "id": "4a4cdff795127ee0",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 66\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNested CV Mean Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmean_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Std: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstd_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     58\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     59\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m20\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meta\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMomentum\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     60\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m30\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meta\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMomentum\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     61\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m20\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meta\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdam\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     62\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m30\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meta\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdam\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m     63\u001B[0m ]\n\u001B[1;32m---> 66\u001B[0m \u001B[43mnested_cross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mouter_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minner_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAdam\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[42], line 31\u001B[0m, in \u001B[0;36mnested_cross_validation\u001B[1;34m(X, y, param_grid, outer_k, inner_k, n_epochs, eta, optimizer)\u001B[0m\n\u001B[0;32m     28\u001B[0m     X_val_inner_scaled \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X_val_inner_scaled, columns\u001B[38;5;241m=\u001B[39mX_val_inner\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m     val_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_perceptron_pytorch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_inner_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_inner_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m     inner_scores\u001B[38;5;241m.\u001B[39mappend(val_acc)\n\u001B[0;32m     34\u001B[0m mean_inner_score \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(inner_scores)\n",
      "Cell \u001B[1;32mIn[41], line 59\u001B[0m, in \u001B[0;36mtrain_perceptron_pytorch\u001B[1;34m(X_train_scaled, X_test_scaled, y_train, y_test, n_epochs, eta, optimizer, params)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (xi, yi) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;66;03m#Compute loss F(w)\u001B[39;00m\n\u001B[0;32m     58\u001B[0m     yi \u001B[38;5;241m=\u001B[39m yi\u001B[38;5;241m.\u001B[39mlong()\n\u001B[1;32m---> 59\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(logits, yi)\n\u001B[0;32m     62\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b963ab3d46b1221f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
